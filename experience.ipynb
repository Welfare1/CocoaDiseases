{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde80b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import hashlib\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Param√®tres\n",
    "base_path = \"detection\"\n",
    "train_images_path = os.path.join(base_path, \"images/train\")\n",
    "val_images_path = os.path.join(base_path, \"images/val\")\n",
    "model_path = \"runs/detect/train6/weights/best.pt\"  # Chemin vers YOLOv8s\n",
    "output_dir = \"InterestData\"  # Dossier pour sauvegarder les ROI\n",
    "output_csv = \"yolo_detections_train_val.csv\"  # Fichier CSV pour les m√©tadonn√©es\n",
    "conf_threshold = 0.6  # Seuil de confiance optimal\n",
    "iou_threshold = 0.45  # Seuil IoU pour NMS\n",
    "iou_match_threshold = 0.3  # Seuil IoU pour appariement\n",
    "min_box_size = 0.1  # Taille minimale normalis√©e pour filtrer les petites bo√Ætes\n",
    "list_disease = {0: \"Fito\", 1: \"Monilia\", 2: \"Sana\"}  # Mapping des classes\n",
    "\n",
    "# Cr√©er le dossier de sortie\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Charger le mod√®le YOLOv8s\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# R√©cup√©rer les images d'entra√Ænement et de validation\n",
    "train_images = glob.glob(os.path.join(train_images_path, \"*.jpg\"))\n",
    "val_images = glob.glob(os.path.join(val_images_path, \"*.jpg\"))\n",
    "all_images = train_images + val_images\n",
    "print(f\"Total images (train + val): {len(all_images)}\")\n",
    "\n",
    "# Fonction pour lire les annotations (v√©rit√©s terrain)\n",
    "def read_yolo_labels(label_path):\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    print(f\"Format incorrect dans {label_path}: {line}\")\n",
    "                    continue\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                labels.append(class_id)\n",
    "                bboxes.append([x_center, y_center, width, height])\n",
    "    return labels, bboxes\n",
    "\n",
    "# Fonction pour calculer l'IoU entre deux bo√Ætes (format YOLO: [x_center, y_center, width, height])\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_min = box1[0] - box1[2] / 2\n",
    "    y1_min = box1[1] - box1[3] / 2\n",
    "    x1_max = box1[0] + box1[2] / 2\n",
    "    y1_max = box1[1] + box1[3] / 2\n",
    "    \n",
    "    x2_min = box2[0] - box2[2] / 2\n",
    "    y2_min = box2[1] - box2[3] / 2\n",
    "    x2_max = box2[0] + box2[2] / 2\n",
    "    y2_max = box2[1] + box2[3] / 2\n",
    "    \n",
    "    x_inter_min = max(x1_min, x2_min)\n",
    "    y_inter_min = max(y1_min, y2_min)\n",
    "    x_inter_max = min(x1_max, x2_max)\n",
    "    y_inter_max = min(y1_max, y2_max)\n",
    "    \n",
    "    inter_area = max(0, x_inter_max - x_inter_min) * max(0, y_inter_max - y_inter_min)\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Liste pour stocker les r√©sultats\n",
    "results = []\n",
    "\n",
    "# Effectuer les pr√©dictions et extraire les ROI\n",
    "for img_path in all_images:\n",
    "    # D√©terminer si l'image est dans train ou val\n",
    "    if \"train\" in img_path:\n",
    "        label_path = img_path.replace(\"images/train\", \"labels/train\").replace(\".jpg\", \".txt\")\n",
    "    else:\n",
    "        label_path = img_path.replace(\"images/val\", \"labels/val\").replace(\".jpg\", \".txt\")\n",
    "    \n",
    "    # Charger l'image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Erreur de chargement de l'image {img_path}\")\n",
    "        continue\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Pr√©dire avec YOLO\n",
    "    results_yolo = model.predict(img_path, conf=conf_threshold, iou=iou_threshold, imgsz=640, verbose=False)\n",
    "    \n",
    "    # R√©cup√©rer les pr√©dictions\n",
    "    pred_classes = []\n",
    "    pred_bboxes = []\n",
    "    pred_scores = []\n",
    "    for result in results_yolo:\n",
    "        if result.boxes is not None:\n",
    "            pred_classes.extend(result.boxes.cls.cpu().numpy().astype(int))\n",
    "            pred_bboxes.extend(result.boxes.xywhn.cpu().numpy())  # xywh normalis√©\n",
    "            pred_scores.extend(result.boxes.conf.cpu().numpy())\n",
    "    \n",
    "    # R√©cup√©rer les v√©rit√©s terrain\n",
    "    gt_classes, gt_bboxes = read_yolo_labels(label_path)\n",
    "    \n",
    "    # Appariement des bo√Ætes bas√© sur l'IoU\n",
    "    used_preds = set()\n",
    "    used_gts = set()\n",
    "    \n",
    "    if pred_bboxes and gt_bboxes:\n",
    "        # Calculer la matrice IoU\n",
    "        iou_matrix = np.zeros((len(pred_bboxes), len(gt_bboxes)))\n",
    "        for i, pred_box in enumerate(pred_bboxes):\n",
    "            for j, gt_box in enumerate(gt_bboxes):\n",
    "                iou_matrix[i, j] = calculate_iou(pred_box, gt_box)\n",
    "        \n",
    "        # Appariement glouton\n",
    "        while np.max(iou_matrix) >= iou_match_threshold:\n",
    "            max_idx = np.unravel_index(np.argmax(iou_matrix), iou_matrix.shape)\n",
    "            pred_idx, gt_idx = max_idx\n",
    "            \n",
    "            pred_class = pred_classes[pred_idx]\n",
    "            gt_class = gt_classes[gt_idx]\n",
    "            pred_box = pred_bboxes[pred_idx]\n",
    "            pred_score = pred_scores[pred_idx]\n",
    "            iou = iou_matrix[max_idx]\n",
    "            \n",
    "            # Filtrer les bo√Ætes trop petites\n",
    "            if pred_box[2] < min_box_size or pred_box[3] < min_box_size:\n",
    "                used_preds.add(pred_idx)\n",
    "                used_gts.add(gt_idx)\n",
    "                iou_matrix[pred_idx, :] = -1\n",
    "                iou_matrix[:, gt_idx] = -1\n",
    "                continue\n",
    "            \n",
    "            # Conversion en coordonn√©es absolues\n",
    "            x_center = pred_box[0] * width\n",
    "            y_center = pred_box[1] * height\n",
    "            box_width = pred_box[2] * width\n",
    "            box_height = pred_box[3] * height\n",
    "            \n",
    "            x_min = int(max(x_center - box_width / 2, 0))\n",
    "            y_min = int(max(y_center - box_height / 2, 0))\n",
    "            x_max = int(min(x_center + box_width / 2, width))\n",
    "            y_max = int(min(y_center + box_height / 2, height))\n",
    "            \n",
    "            # Extraction de la ROI\n",
    "            roi = img[y_min:y_max, x_min:x_max]\n",
    "            if roi.size == 0:\n",
    "                print(f\"ROI vide pour {img_path}, bo√Æte {pred_idx}\")\n",
    "                continue\n",
    "            \n",
    "            # G√©n√©ration d'un identifiant unique\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            hash_object = hashlib.md5(f\"{base_name}_class{pred_class}_roi{pred_idx}\".encode())\n",
    "            identifiant = hash_object.hexdigest()[:8]\n",
    "            \n",
    "            # Sauvegarde de la ROI\n",
    "            output_filename = f\"class{pred_class}_{identifiant}.jpg\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            cv2.imwrite(output_path, roi)\n",
    "            print(f\"ROI enregistr√©e: {output_path}\")\n",
    "            \n",
    "            # Stocker les m√©tadonn√©es\n",
    "            results.append({\n",
    "                \"image_path\": img_path,\n",
    "                \"output_path\": output_path,\n",
    "                \"pred_x_center\": pred_box[0],\n",
    "                \"pred_y_center\": pred_box[1],\n",
    "                \"pred_width\": pred_box[2],\n",
    "                \"pred_height\": pred_box[3],\n",
    "                \"pred_class\": pred_class,\n",
    "                \"pred_class_name\": list_disease[pred_class],\n",
    "                \"gt_class\": gt_class,\n",
    "                \"gt_class_name\": list_disease[gt_class],\n",
    "                \"confidence\": pred_score,\n",
    "                \"iou\": iou,\n",
    "                \"dataset\": \"train\" if \"train\" in img_path else \"val\"\n",
    "            })\n",
    "            \n",
    "            used_preds.add(pred_idx)\n",
    "            used_gts.add(gt_idx)\n",
    "            iou_matrix[pred_idx, :] = -1\n",
    "            iou_matrix[:, gt_idx] = -1\n",
    "    \n",
    "    # Ajouter les pr√©dictions non appari√©es (optionnel)\n",
    "    for i, pred_class in enumerate(pred_classes):\n",
    "        if i not in used_preds:\n",
    "            pred_box = pred_bboxes[i]\n",
    "            if pred_box[2] < min_box_size or pred_box[3] < min_box_size:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"image_path\": img_path,\n",
    "                \"output_path\": None,\n",
    "                \"pred_x_center\": pred_box[0],\n",
    "                \"pred_y_center\": pred_box[1],\n",
    "                \"pred_width\": pred_box[2],\n",
    "                \"pred_height\": pred_box[3],\n",
    "                \"pred_class\": pred_class,\n",
    "                \"pred_class_name\": list_disease[pred_class],\n",
    "                \"gt_class\": None,\n",
    "                \"gt_class_name\": None,\n",
    "                \"confidence\": pred_scores[i],\n",
    "                \"iou\": 0.0,\n",
    "                \"dataset\": \"train\" if \"train\" in img_path else \"val\"\n",
    "            })\n",
    "\n",
    "# Convertir les r√©sultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sauvegarder les r√©sultats dans un fichier CSV\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s dans {output_csv}\")\n",
    "\n",
    "# Afficher un aper√ßu des r√©sultats\n",
    "print(\"\\nüìä Aper√ßu des r√©sultats :\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Statistiques\n",
    "total_predictions = len(results_df[results_df[\"pred_class\"].notnull()])\n",
    "total_gt = len(results_df[results_df[\"gt_class\"].notnull()])\n",
    "matched = len(results_df[(results_df[\"pred_class\"].notnull()) & (results_df[\"gt_class\"].notnull())])\n",
    "print(f\"\\nüìä Statistiques :\")\n",
    "print(f\"Total pr√©dictions : {total_predictions}\")\n",
    "print(f\"Total v√©rit√©s terrain : {total_gt}\")\n",
    "print(f\"Appariements r√©ussis : {matched}\")\n",
    "print(f\"Pourcentage d'appariement : {matched / total_gt * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6141185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "source_dir = \"InterestData\"\n",
    "\n",
    "train_dir = \"Dataset/train\"\n",
    "val_dir = \"Dataset/validation\"\n",
    "split_ratio = 0.8  # 80% train / 20% validation\n",
    "\n",
    "# Cr√©ation des r√©pertoires\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Dictionnaire pour regrouper les fichiers par classe\n",
    "class_files = {}\n",
    "\n",
    "# Remplir le dictionnaire avec les fichiers class√©s par classe\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        try:\n",
    "            class_id = filename.split(\"_\")[0][5:]  # Extraction du class_id\n",
    "            class_files.setdefault(class_id, []).append(filename)\n",
    "        except:\n",
    "            print(f\"Format invalide pour {filename}\")\n",
    "            continue\n",
    "\n",
    "# R√©partition stratifi√©e\n",
    "for class_id, files in class_files.items():\n",
    "    random.shuffle(files)  # M√©lange al√©atoire\n",
    "    split_idx = int(len(files) * split_ratio)\n",
    "    \n",
    "    # D√©placement vers train\n",
    "    for file in files[:split_idx]:\n",
    "        src = os.path.join(source_dir, file)\n",
    "        dst = os.path.join(train_dir, file)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    # D√©placement vers validation\n",
    "    for file in files[split_idx:]:\n",
    "        src = os.path.join(source_dir, file)\n",
    "        dst = os.path.join(val_dir, file)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(f\"R√©partition termin√©e :\")\n",
    "print(f\"- Train: {len(os.listdir(train_dir))} images\")\n",
    "print(f\"- Validation: {len(os.listdir(val_dir))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc8b57",
   "metadata": {},
   "source": [
    "## IMPLEMENTATION CONVNEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\n",
    "# Fixer les graines pour la reproductibilit√©\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Param√®tres\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "num_classes = 3  # Adapt√© √† vos 3 maladies\n",
    "\n",
    "# Param√®tres d'augmentation\n",
    "augmentation_params = {\n",
    "    \"flip_horizontal\": True,  # Retournement horizontal\n",
    "    \"flip_vertical\": True,   # Retournement vertical\n",
    "    \"rotation\": 30.0,        # Rotation max en degr√©s\n",
    "    \"zoom\": 0.2,             # Zoom max (0.2 = ¬±20%)\n",
    "    \"translation_height\": 0.1,  # Translation max verticale (10% de l'image)\n",
    "    \"translation_width\": 0.1,\n",
    "    \"brightness\": 0.2,       # Variation max de luminosit√©\n",
    "    \"contrast\": [0.8, 1.2],  # Plage de contraste\n",
    "    \"noise_std\": 10.0,       # √âcart-type du bruit gaussien\n",
    "    \"crop\": 0.1              # Recadrage al√©atoire max (10% de l'image)\n",
    "}\n",
    "\n",
    "# D√©finir la couche RandomTranslation globalement\n",
    "translation_layer = tf.keras.layers.RandomTranslation(\n",
    "    height_factor=augmentation_params[\"translation_height\"],\n",
    "    width_factor=augmentation_params[\"translation_width\"],\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Fonctions utilitaires pour le pipeline\n",
    "# Pipeline de donn√©es avec augmentation\n",
    "def parse_image(filename):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = tf.keras.applications.convnext.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def augment_image(image, params):\n",
    "    # Flip horizontal et vertical\n",
    "    if params[\"flip_horizontal\"]:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "    if params[\"flip_vertical\"]:\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    # Rotation\n",
    "    if params[\"rotation\"] > 0:\n",
    "        angle = tf.random.uniform([], -params[\"rotation\"] * np.pi / 180, params[\"rotation\"] * np.pi / 180)\n",
    "        image = tf.image.rot90(image, k=tf.cast(angle / (np.pi / 2), tf.int32))\n",
    "    \n",
    "    # Zoom\n",
    "    if params[\"zoom\"] > 0:\n",
    "        scale = tf.random.uniform([], 1 - params[\"zoom\"], 1 + params[\"zoom\"])\n",
    "        new_size = tf.cast(tf.cast(img_size, tf.float32) * scale, tf.int32)\n",
    "        image = tf.image.resize(image, new_size)\n",
    "        image = tf.image.resize_with_crop_or_pad(image, img_size[0], img_size[1])\n",
    "    \n",
    "    # Translation (utilisation de la couche globale)\n",
    "    if params[\"translation_height\"] > 0 or params[\"translation_width\"] > 0:\n",
    "        image = translation_layer(image)\n",
    "    \n",
    "    # Luminosit√©\n",
    "    if params[\"brightness\"] > 0:\n",
    "        image = tf.image.random_brightness(image, max_delta=params[\"brightness\"])\n",
    "    \n",
    "    # Contraste\n",
    "    if params[\"contrast\"][0] < params[\"contrast\"][1]:\n",
    "        image = tf.image.random_contrast(image, lower=params[\"contrast\"][0], upper=params[\"contrast\"][1])\n",
    "    \n",
    "    # Bruit gaussien\n",
    "    if params[\"noise_std\"] > 0:\n",
    "        noise = tf.random.normal(tf.shape(image), stddev=params[\"noise_std\"])\n",
    "        image = image + noise\n",
    "    \n",
    "    # Recadrage al√©atoire\n",
    "    if params[\"crop\"] > 0:\n",
    "        crop_size = tf.cast(tf.cast(img_size, tf.float32) * (1 - params[\"crop\"]), tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size[0], crop_size[1], 3])\n",
    "        image = tf.image.resize(image, img_size)\n",
    "    \n",
    "    # Clip pour √©viter des valeurs aberrantes\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    return image\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    fname = tf.strings.split(filename, os.sep)[-1]\n",
    "    label_str = tf.strings.regex_replace(fname, \"^class\", \"\")\n",
    "    label_str = tf.strings.split(label_str, \"_\")[0]\n",
    "    label = tf.strings.to_number(label_str, out_type=tf.int32)\n",
    "    return tf.one_hot(label, depth=num_classes)\n",
    "\n",
    "def load_and_preprocess_image(filename, augment=False):\n",
    "    image = parse_image(filename)\n",
    "    if augment:\n",
    "        image = augment_image(image, augmentation_params)\n",
    "    label = get_label_from_filename(filename)\n",
    "    return image, label\n",
    "\n",
    "# Cr√©ation des datasets\n",
    "train_files = tf.data.Dataset.list_files(os.path.join(train_dir, \"*.jpg\"), shuffle=True)\n",
    "val_files = tf.data.Dataset.list_files(os.path.join(val_dir, \"*.jpg\"), shuffle=False)\n",
    "\n",
    "train_ds = train_files.map(lambda x: load_and_preprocess_image(x, augment=True), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_files.map(lambda x: load_and_preprocess_image(x, augment=False), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Regroupement en batches et optimisation par prefetch\n",
    "train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds  = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier la taille de train_ds via cardinality (optionnel)\n",
    "train_size = tf.data.experimental.cardinality(train_files).numpy()\n",
    "print(f\"Taille de train_ds (images avant batching) : {train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ad951",
   "metadata": {},
   "source": [
    "### 1-Cr√©ation du mod√®le ConvNeXtSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387fb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Construction du mod√®le avec ConvNeXtSmall\n",
    "# -------------------------------------------\n",
    "\n",
    "# Charger la base pr√©-entra√Æn√©e ConvNeXtSmall sans la t√™te (include_top=False)\n",
    "# Cr√©ation du mod√®le ConvNeXtSmall\n",
    "base_model = tf.keras.applications.ConvNeXtSmall(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_size[0], img_size[1], 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(img_size[0], img_size[1], 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0816f14d",
   "metadata": {},
   "source": [
    "#### Entra√Ænement initial et Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3994a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# √âtape 2 et 3 : Entra√Ænement initial et Fine-tuning\n",
    "# -------------------------------------------\n",
    "\n",
    "# Entra√Ænement initial (seulement la nouvelle t√™te)\n",
    "# Entra√Ænement initial\n",
    "initial_epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint, early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = int(len(base_model.layers) * 0.8)\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "\n",
    "fine_tune_epochs = 20\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint, early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2b84d",
   "metadata": {},
   "source": [
    "#### Evaluation du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c243dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Fito\", \"Monilia\", \"Sana\"]\n",
    "# √âvaluation\n",
    "y_pred_prob = model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.concatenate([np.argmax(labels.numpy(), axis=1) for _, labels in val_ds])\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b68f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_perc = (cm / cm.sum(axis=1, keepdims=True).astype(float)) * 100\n",
    "labels = np.array([[f\"{cm[i,j]}\\n({cm_perc[i,j]:.1f}%)\" for j in range(num_classes)] for i in range(num_classes)])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Classe pr√©dite\")\n",
    "plt.ylabel(\"Classe r√©elle\")\n",
    "plt.title(\"Matrice de confusion ConvNeXt\")\n",
    "plt.savefig(\"svg/ConfusionMatrix.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'entra√Ænement\n",
    "def save_and_show_plot(x, y_train, y_val, title, ylabel, filename):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(x, y_train, label=f\"Training {ylabel}\")\n",
    "    plt.plot(x, y_val, label=f\"Validation {ylabel}\")\n",
    "    plt.axvline(x=initial_epochs, color='r', linestyle='--', label=\"D√©but Fine-Tuning\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"√âpoques\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.savefig(f\"svg/{filename}\", format=\"svg\")\n",
    "    plt.show()\n",
    "\n",
    "#Mapper les cl√©s correspondantes pour combiner les historiques\n",
    "history_combined = {}\n",
    "metric_mapping = {\n",
    "    'loss': 'loss',\n",
    "    'accuracy': 'accuracy',\n",
    "    'val_loss': 'val_loss',\n",
    "    'val_accuracy': 'val_accuracy',\n",
    "    'precision': 'precision_1',  # Mapper precision √† precision_1 pour history_fine\n",
    "    'recall': 'recall_1',        # Mapper recall √† recall_1 pour history_fine\n",
    "    'val_precision': 'val_precision_1',\n",
    "    'val_recall': 'val_recall_1'\n",
    "}\n",
    "\n",
    "for orig_key, fine_key in metric_mapping.items():\n",
    "    if orig_key in history.history and fine_key in history_fine.history:\n",
    "        history_combined[orig_key] = history.history[orig_key] + history_fine.history[fine_key]\n",
    "    else:\n",
    "        print(f\"Cl√© manquante : {orig_key} ou {fine_key}\")\n",
    "\n",
    "# Ignorer learning_rate (non n√©cessaire pour les courbes)\n",
    "if 'learning_rate' in history_combined:\n",
    "    del history_combined['learning_rate']\n",
    "\n",
    "# V√©rifier les cl√©s combin√©es\n",
    "print(\"Cl√©s dans history_combined:\", list(history_combined.keys()))\n",
    "\n",
    "epochs_range = range(1, len(history_combined.get(\"accuracy\", [])) + 1)\n",
    "\n",
    "# Tracer les m√©triques disponibles\n",
    "if 'accuracy' in history_combined:\n",
    "    save_and_show_plot(epochs_range, history_combined[\"accuracy\"], history_combined[\"val_accuracy\"], \"Courbe d'Accuracy\", \"Accuracy\", \"accuracy.svg\")\n",
    "if 'loss' in history_combined:\n",
    "    save_and_show_plot(epochs_range, history_combined[\"loss\"], history_combined[\"val_loss\"], \"Courbe de Perte\", \"Loss\", \"loss.svg\")\n",
    "if 'precision' in history_combined:\n",
    "    save_and_show_plot(epochs_range, history_combined[\"precision\"], history_combined[\"val_precision\"], \"Courbe de Pr√©cision\", \"Precision\", \"precision.svg\")\n",
    "if 'recall' in history_combined:\n",
    "    save_and_show_plot(epochs_range, history_combined[\"recall\"], history_combined[\"val_recall\"], \"Courbe de Rappel\", \"Recall\", \"recall.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b813bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle([\"blue\", \"red\", \"green\"])\n",
    "for i, color in zip(range(num_classes), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_true == i, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"Taux de faux positifs\")\n",
    "plt.ylabel(\"Taux de vrais positifs\")\n",
    "plt.title(\"Courbes ROC par classe\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"svg/ROC-AUC.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aaf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Visualisation des erreurs\n",
    "df_errors = pd.DataFrame({\n",
    "    \"file_path\": [f.numpy().decode() for f in val_files],\n",
    "    \"true_label\": y_true,\n",
    "    \"pred_label\": y_pred,\n",
    "    \"confidence\": np.max(y_pred_prob, axis=1)\n",
    "})\n",
    "df_errors = df_errors[df_errors[\"true_label\"] != df_errors[\"pred_label\"]]\n",
    "print(f\"\\nNombre d'erreurs : {len(df_errors)}\")\n",
    "print(df_errors.head())\n",
    "\n",
    "for idx, row in df_errors.head(5).iterrows():\n",
    "    img = cv2.imread(row[\"file_path\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Vrai: {class_names[int(row['true_label'])]} - Pr√©dit: {class_names[int(row['pred_label'])]}, Confiance: {row['confidence']:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le\n",
    "model.save(\"Model/convnext_small_final3.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
