import os
import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from ultralytics import YOLO
from PIL import Image
import joblib  # Importation de joblib

# D√©sactiver les optimisations oneDNN dans TensorFlow
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# --------------------------
# 1. Chargement des mod√®les
# --------------------------

st.sidebar.title("Configuration")

try:
    # Charger le mod√®le YOLOv8 personnalis√© pour la d√©tection des f√®ves de cacao.
    model_yolo = YOLO("Model/model_cacao.pt")

    # Charger le mod√®le de classification bas√© sur ConvNeXtSmall
    # Charger le mod√®le de classification bas√© sur ConvNeXtSmall (d√©j√† entra√Æn√©)
    classifier = tf.keras.models.load_model("Model/modele_convnext_small_mine_tf(e50).keras", compile=False)

    svm_clf = joblib.load("Model/best_svm_SIEL.pkl")

    st.sidebar.success("Mod√®les charg√©s avec succ√®s ‚úÖ")
except Exception as e:
    st.sidebar.error(f"Erreur lors du chargement des mod√®les : {e}")
    st.stop()

# D√©finir les noms des classes de maladies (3 classes dans cet exemple)
target_names = ["class0", "class1", "class2"]

# Couleurs des cadres pour chaque classe
class_colors = {
    "class0": (255, 0, 0),   # Rouge
    "class1": (0, 0, 255),   # Bleu
    "class2": (255, 255, 0)  # Jaune
}

# --------------------------
# 2. Fonction de traitement
# --------------------------

def extract_features(image, model):
    img_resized = cv2.resize(image, (224, 224))
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    img_preprocessed = tf.keras.applications.convnext.preprocess_input(np.array(img_rgb, dtype=np.float32))
    img_preprocessed = np.expand_dims(img_preprocessed, axis=0)
    features = model.predict(img_preprocessed)
    return features.squeeze()


def process_image(image, use_svm=False):
    if image is None:
        st.error("L'image charg√©e est invalide. Veuillez r√©essayer.")
        return None
    
    # Appliquer le mod√®le YOLOv8 pour d√©tecter les f√®ves
    results = model_yolo(image)

    # R√©cup√©rer les bo√Ætes englobantes
    boxes = results[0].boxes
    if boxes is None:
        st.warning("Aucune f√®ve d√©tect√©e dans l'image.")
        return image

    xyxy = boxes.xyxy.cpu().numpy()
    confidences = boxes.conf.cpu().numpy()

    # Filtrer les d√©tections avec un seuil de confiance
    detections_list = []
    confidence_threshold = st.sidebar.slider("Seuil de confiance YOLO", 0.0, 1.0, 0.5, 0.05)
    
    for i in range(len(xyxy)):
        if confidences[i] < confidence_threshold:
            continue
        x1, y1, x2, y2 = map(int, xyxy[i])
        detections_list.append((x1, y1, x2, y2, confidences[i]))

    if not detections_list:
        st.warning("Aucune f√®ve n'a √©t√© retenue apr√®s filtrage.")
        return image
    
    # Copie de l'image pour annoter les r√©sultats
    output_img = image.copy()

    # Pour chaque d√©tection, extraire la ROI, la classifier et afficher le r√©sultat
    for (x1, y1, x2, y2, conf_det) in detections_list:
        # Extraire la r√©gion d'int√©r√™t correspondant √† la f√®ve
        roi = image[y1:y2, x1:x2]

        if roi.size == 0:
            continue

        # Pr√©paration de la ROI pour le mod√®le de classification
        features = extract_features(roi, classifier)
        
        if use_svm:
            pred_class = svm_clf.predict([features])[0]
            confidence_class = 1.0  # SVM ne fournit pas directement une probabilit√©
        else:
            pred_prob = classifier.predict(np.array([features]))  # Correction de la ligne
            pred_class = np.argmax(pred_prob, axis=1)[0]
            confidence_class = np.max(pred_prob)

        # Cr√©ation du label √† afficher
        class_name = target_names[pred_class]
        label_text = f"{class_name} ({confidence_class:.2f})"

        # Dessiner la bounding box sur l'image de sortie
        color = class_colors.get(class_name, (255, 255, 255))  # Blanc par d√©faut
        cv2.rectangle(output_img, (x1, y1), (x2, y2), color, 3)  # √âpaisseur du cadre augment√©e √† 3
        cv2.putText(output_img, label_text, (x1, max(y1 - 10, 0)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    return output_img

# --------------------------
# 3. Interface Streamlit
# --------------------------

st.title("D√©tection et Classification des F√®ves de Cacao üç´")
st.write("T√©l√©chargez une image pour d√©tecter et classifier les f√®ves de cacao.")

# Option pour choisir le mod√®le de classification
model_choice = st.sidebar.radio("Choisissez le mod√®le de classification :", ["ConvNeXt seul", "ConvNeXt + SVM"])

uploaded_file = st.file_uploader("Choisissez une image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Lire l'image t√©l√©charg√©e
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, 1)

    if image is not None:
        # Traiter l'image
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        use_svm = (model_choice == "ConvNeXt + SVM")
        output_img = process_image(image, use_svm=use_svm)
        
        if output_img is not None:
            # Afficher les images
            st.image(image, caption='Image Originale', use_column_width=True)
            st.image(output_img, caption='Image avec D√©tections et Classifications', use_column_width=True)
    else:
        st.error("Impossible de lire l'image. Veuillez r√©essayer avec une autre image.")
